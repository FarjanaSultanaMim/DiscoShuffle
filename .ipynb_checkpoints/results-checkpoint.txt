BEST:

Earlystopping = 15, Bidirectional_GRU

############################################## TN16
CUDA_VISIBLE_DEVICES=0 python src/train.py \
    --fold 1 \
    --model-type nea --dropout 0.7 \
    --embedding-dim 50 --aggregation-GRUdim 300 \
    --gradientclipnorm 5 --meanovertime \
    --pre-trained --fix-embedding
    
fold_0: MSE: 0.3591114599841626, MAE: 0.42943344593048094
fold_1: MSE: 0.3285123512777851, MAE: 0.4121524077742847
fold_2: MSE: 0.43354450692478946, MAE: 0.43820441302968494
fold_3: MSE: 0.31550909529180166, MAE: 0.43711961561174534
fold_4: MSE: 0.38192183534304036, MAE: 0.4812223768234253

******** MSE:0.3637198, MAE: 0.4396265

CUDA_VISIBLE_DEVICES=0 python src/train.py \
    --fold 1 \
    --model-type nea --dropout 0.5 \
    --embedding-dim 50 --aggregation-GRUdim 300 \
    --gradientclipnorm 0 --meanovertime \
    --pre-trained --fix-embedding
    
fold_0: MSE: 0.3782834103218551, MAE: 0.44949509382247926
fold_1: MSE: 0.30762365773575506, MAE: 0.4080018593897274
fold_2: MSE: 0.40797221091868885, MAE: 0.4221186768356247
fold_3: MSE: 0.31177358090172874, MAE: 0.42847541078406187
fold_4: MSE: 0.3472692411345298, MAE: 0.43102340459823607

******** MSE: 0.3505844, MAE: 0.4278229


############################################################ TN16+PN10

CUDA_VISIBLE_DEVICES=0 python src/train.py     --fold 0     --model-type nea --dropout 0.5     --embedding-dim 50 --aggregation-grudim 300     --gradientclipnorm 0 --meanovertime     --pre-trained --fix-embedding     --persing-seq --pseq-embedding-dim 16 --pseq-encoder-dim 400

fold_0: MSE: 0.18049116845715346, MAE: 0.346776248216629
fold_1: MSE: 0.1895655062736181, MAE: 0.3554454336118935
fold_2: MSE: 0.21197400929878285, MAE: 0.3720405943951203
fold_3: MSE: 0.21299012946995527, MAE: 0.3614097293929674
fold_4: MSE: 0.2142416032639801, MAE: 0.3638330030441284

MSE: 0.2018525, MAE: 0.3599010

CUDA_VISIBLE_DEVICES=0 python src/train.py     --fold 1     --model-type nea --dropout 0.5     --embedding-dim 50 --aggregation-grudim 300     --gradientclipnorm 0 --meanovertime     --pre-trained --fix-embedding     --persing-seq --pseq-embedding-dim 16 --pseq-encoder-dim 400

fold_0: MSE: 0.17061031837492258, MAE: 0.33038390934467315
fold_1: MSE: 0.1632769011297618, MAE: 0.3271820171555476
fold_2: MSE: 0.17779864181921629, MAE: 0.34335210489396434
fold_3: MSE: 0.20953272499181347, MAE: 0.3518696169355022
fold_4: MSE: 0.20067415570347982, MAE: 0.3515308684110641

MSE: 0.1843785

CUDA_VISIBLE_DEVICES=0 python src/train.py     --fold 1     --model-type nea --dropout 0.5     --embedding-dim 50 --aggregation-grudim 300     --gradientclipnorm 0 --meanovertime     --pre-trained --fix-embedding     --persing-seq --pseq-embedding-dim 16 --pseq-encoder-dim 400 ##bidirectional LSTM

fold_0:
fold_1:
fold_2:
fold_3: MSE: 0.2065341468676142, MAE: 0.3557260006814454
fold_4:

######################################################## Sentence pretraining

CUDA_VISIBLE_DEVICES=0 python src/train_enc.py     --model-type nea --dropout 0.7     --embedding-dim 50 --aggregation-grudim 300     --gradientclipnorm 5 --meanovertime     --shuffle-type sentence

****** Val_accuracy: 0.7314
       Val_accuracy: 0.7516//where best loss was taken
       7315


####################################################### # TN16+PN10+pretrain(sent. shuffle, not fixed)

CUDA_VISIBLE_DEVICES=0 python src/train.py --fold 0 --model-type nea_aft_pretrain --dropout 0.5 --embedding-dim 50 --aggregation-grudim 300 --gradientclipnorm 0 --meanovertime --persing-seq --pseq-embedding-dim 16 --pseq-encoder-dim 400 --pretrained-encoder output_enc/sent_best_loss


fold_0: MSE: 0.1743746673722115, MAE: 0.34336245119571684
fold_1: MSE: 0.1795936046999991, MAE: 0.345465230111459
fold_2: MSE: 0.17682434629933422,MAE: 0.34813615694567934
fold_3: MSE: 0.21498837168131665, MAE: 0.3672917565303062
fold_4: MSE: 0.22191583814627777, MAE: 0.3657341432571411

MSE: 0.1935394

fold_0: MSE: 0.16989462223612783, MAE: 0.33331760346889494
fold_1:
fold_2:
fold_3:
fold_4:

enc_fixed:

fold_3: MSE: 0.21684248200098613, MAE: 0.368384879619921























fold_0:
fold_1:
fold_2:
fold_3:
fold_4: