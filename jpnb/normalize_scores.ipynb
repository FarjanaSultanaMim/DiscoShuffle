{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"/home/mim/ICLE_essay_Wprompt.xlsx\"\n",
    "df_ic=pd.ExcelFile(file)\n",
    "dff= df_ic.parse('Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_scored_df(df):\n",
    "    dff=df\n",
    "    dff['n_score']=\"\"\n",
    "    \n",
    "    scaler1=MinMaxScaler()\n",
    "    #essay_set1=dff[dff.essay_set == 1]\n",
    "    score1=[]\n",
    "    for i in range(dff.index[0],(dff.index[-1]+1)):\n",
    "        score1.append(dff.at[i,'Organization'])\n",
    "    score1_n=np.asarray(score1) \n",
    "    score1_reshape=score1_n.reshape(-1,1)\n",
    "    scaler1.fit(score1_reshape)\n",
    "    score1_normalized=scaler1.transform(score1_reshape)\n",
    "    score1_normalized=score1_normalized.tolist()\n",
    "    score1_normalized_df=[]\n",
    "    for i in score1_normalized:\n",
    "        for j in i:\n",
    "            score1_normalized_df.append(j)\n",
    "    dff['n_score']=score1_normalized_df\n",
    "                        \n",
    "    return dff, scaler1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df, s1=normalized_scored_df(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.666667\n",
       "1       0.666667\n",
       "2       0.500000\n",
       "3       0.666667\n",
       "4       0.666667\n",
       "5       0.500000\n",
       "6       0.500000\n",
       "7       0.666667\n",
       "8       0.666667\n",
       "9       0.666667\n",
       "10      0.833333\n",
       "11      0.666667\n",
       "12      0.666667\n",
       "13      0.500000\n",
       "14      0.666667\n",
       "15      0.500000\n",
       "16      0.666667\n",
       "17      0.666667\n",
       "18      0.833333\n",
       "19      0.500000\n",
       "20      0.666667\n",
       "21      0.666667\n",
       "22      0.833333\n",
       "23      0.666667\n",
       "24      0.666667\n",
       "25      0.833333\n",
       "26      0.500000\n",
       "27      0.833333\n",
       "28      0.666667\n",
       "29      0.500000\n",
       "          ...   \n",
       "973     0.833333\n",
       "974     0.833333\n",
       "975     0.666667\n",
       "976     0.666667\n",
       "977     0.666667\n",
       "978     0.833333\n",
       "979     0.666667\n",
       "980     0.666667\n",
       "981     0.500000\n",
       "982     0.666667\n",
       "983     0.666667\n",
       "984     0.666667\n",
       "985     0.666667\n",
       "986     0.666667\n",
       "987     0.500000\n",
       "988     0.666667\n",
       "989     0.333333\n",
       "990     0.666667\n",
       "991     0.666667\n",
       "992     0.666667\n",
       "993     0.666667\n",
       "994     0.500000\n",
       "995     0.666667\n",
       "996     0.500000\n",
       "997     0.666667\n",
       "998     0.500000\n",
       "999     0.666667\n",
       "1000    0.833333\n",
       "1001    0.833333\n",
       "1002    1.000000\n",
       "Name: n_score, Length: 1003, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=normalized_df\n",
    "df.n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerfile = 's1.sav'\n",
    "pickle.dump(s1, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for i in range(0,10):\n",
    "    test.append(df.at[i,'Organization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3. ],\n",
       "       [3. ],\n",
       "       [2.5],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.asarray(test)\n",
    "test = test.reshape(-1,1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3d5e3a62a6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_scaled_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_scaled_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "scaler = pickle.load(open(scalerfile, 'rb'))\n",
    "test_scaled_set = scaler.transform(test)\n",
    "pp = test_scaled_set.tolist()\n",
    "pp.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
